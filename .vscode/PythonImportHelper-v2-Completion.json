[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "genfromtxt",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "Pipeline",
        "importPath": "sklearn.pipeline",
        "description": "sklearn.pipeline",
        "isExtraImport": true,
        "detail": "sklearn.pipeline",
        "documentation": {}
    },
    {
        "label": "make_pipeline",
        "importPath": "sklearn.pipeline",
        "description": "sklearn.pipeline",
        "isExtraImport": true,
        "detail": "sklearn.pipeline",
        "documentation": {}
    },
    {
        "label": "Pipeline",
        "importPath": "sklearn.pipeline",
        "description": "sklearn.pipeline",
        "isExtraImport": true,
        "detail": "sklearn.pipeline",
        "documentation": {}
    },
    {
        "label": "make_classification",
        "importPath": "sklearn.datasets",
        "description": "sklearn.datasets",
        "isExtraImport": true,
        "detail": "sklearn.datasets",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "label_binarize",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "PowerTransformer",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "LabelEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "GridSearchCV",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "LeavePOut",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KNeighborsClassifier",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "KNeighborsClassifier",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "KNeighborsClassifier",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "KNeighborsClassifier",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "KNeighborsClassifier",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "SelectKBest",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "mutual_info_classif",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "f_classif",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "SelectKBest",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "RFE",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "SelectFdr",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "f_classif",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "SelectKBest",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "SelectFdr",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "SelectFdr",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "chi2",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "f_classif",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "RFE",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "VarianceThreshold",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "rand",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "rand",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "choice",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "rand",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "choice",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "heapq",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "heapq",
        "description": "heapq",
        "detail": "heapq",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "scipy.io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.io",
        "description": "scipy.io",
        "detail": "scipy.io",
        "documentation": {}
    },
    {
        "label": "arff",
        "importPath": "scipy.io",
        "description": "scipy.io",
        "isExtraImport": true,
        "detail": "scipy.io",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "freeze_support",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Process",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "statistics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "statistics",
        "description": "statistics",
        "detail": "statistics",
        "documentation": {}
    },
    {
        "label": "chi2_contingency",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "process_map",
        "importPath": "tqdm.contrib.concurrent",
        "description": "tqdm.contrib.concurrent",
        "isExtraImport": true,
        "detail": "tqdm.contrib.concurrent",
        "documentation": {}
    },
    {
        "label": "faiss",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faiss",
        "description": "faiss",
        "detail": "faiss",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "matthews_corrcoef",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "average_precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "make_scorer",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "matthews_corrcoef",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "average_precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_recall_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "pairwise_distances",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "reverse_argsort",
        "importPath": "skfeature.utility.util",
        "description": "skfeature.utility.util",
        "isExtraImport": true,
        "detail": "skfeature.utility.util",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "over_sampling",
        "importPath": "imblearn",
        "description": "imblearn",
        "isExtraImport": true,
        "detail": "imblearn",
        "documentation": {}
    },
    {
        "label": "RandomOverSampler",
        "importPath": "imblearn.over_sampling",
        "description": "imblearn.over_sampling",
        "isExtraImport": true,
        "detail": "imblearn.over_sampling",
        "documentation": {}
    },
    {
        "label": "KernelPCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "listdir",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "listdir",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "GaussianNB",
        "importPath": "sklearn.naive_bayes",
        "description": "sklearn.naive_bayes",
        "isExtraImport": true,
        "detail": "sklearn.naive_bayes",
        "documentation": {}
    },
    {
        "label": "GaussianNB",
        "importPath": "sklearn.naive_bayes",
        "description": "sklearn.naive_bayes",
        "isExtraImport": true,
        "detail": "sklearn.naive_bayes",
        "documentation": {}
    },
    {
        "label": "isfile",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "isfile",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dssa",
        "importPath": "feature_algo",
        "description": "feature_algo",
        "isExtraImport": true,
        "detail": "feature_algo",
        "documentation": {}
    },
    {
        "label": "New_dssa",
        "importPath": "feature_algo",
        "description": "feature_algo",
        "isExtraImport": true,
        "detail": "feature_algo",
        "documentation": {}
    },
    {
        "label": "dssa",
        "importPath": "feature_algo",
        "description": "feature_algo",
        "isExtraImport": true,
        "detail": "feature_algo",
        "documentation": {}
    },
    {
        "label": "New_dssa",
        "importPath": "feature_algo",
        "description": "feature_algo",
        "isExtraImport": true,
        "detail": "feature_algo",
        "documentation": {}
    },
    {
        "label": "MRMR",
        "importPath": "skfeature.function.information_theoretical_based",
        "description": "skfeature.function.information_theoretical_based",
        "isExtraImport": true,
        "detail": "skfeature.function.information_theoretical_based",
        "documentation": {}
    },
    {
        "label": "MRMR",
        "importPath": "skfeature.function.information_theoretical_based",
        "description": "skfeature.function.information_theoretical_based",
        "isExtraImport": true,
        "detail": "skfeature.function.information_theoretical_based",
        "documentation": {}
    },
    {
        "label": "ReliefF",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ReliefF",
        "description": "ReliefF",
        "detail": "ReliefF",
        "documentation": {}
    },
    {
        "label": "comparison",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "comparison",
        "description": "comparison",
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "get_fold",
        "importPath": "comparison",
        "description": "comparison",
        "isExtraImport": true,
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "evalute",
        "importPath": "comparison",
        "description": "comparison",
        "isExtraImport": true,
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "feature_selection",
        "importPath": "comparison",
        "description": "comparison",
        "isExtraImport": true,
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "default_timer",
        "importPath": "timeit",
        "description": "timeit",
        "isExtraImport": true,
        "detail": "timeit",
        "documentation": {}
    },
    {
        "label": "default_timer",
        "importPath": "timeit",
        "description": "timeit",
        "isExtraImport": true,
        "detail": "timeit",
        "documentation": {}
    },
    {
        "label": "utlis",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "utlis",
        "description": "utlis",
        "detail": "utlis",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "BaseEstimator",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "TransformerMixin",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "BaseEstimator",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "TransformerMixin",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "feature_algo.reliefF",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "feature_algo.reliefF",
        "description": "feature_algo.reliefF",
        "detail": "feature_algo.reliefF",
        "documentation": {}
    },
    {
        "label": "Genetic_FA",
        "importPath": "feature_algo.Genetic_FA",
        "description": "feature_algo.Genetic_FA",
        "isExtraImport": true,
        "detail": "feature_algo.Genetic_FA",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "MyPool",
        "importPath": "utlis.utlis",
        "description": "utlis.utlis",
        "isExtraImport": true,
        "detail": "utlis.utlis",
        "documentation": {}
    },
    {
        "label": "turn_resDict_to_df",
        "importPath": "utlis.utlis",
        "description": "utlis.utlis",
        "isExtraImport": true,
        "detail": "utlis.utlis",
        "documentation": {}
    },
    {
        "label": "SimpleImputer",
        "importPath": "sklearn.impute",
        "description": "sklearn.impute",
        "isExtraImport": true,
        "detail": "sklearn.impute",
        "documentation": {}
    },
    {
        "label": "sleep",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "Genetic_FA",
        "kind": 6,
        "importPath": "feature_algo.Genetic_FA",
        "description": "feature_algo.Genetic_FA",
        "peekOfCode": "class Genetic_FA():\n    # def __init__(self ) -> None:\n    def fit(self,X,y):\n        #split the data into train and validation\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n        self.n_features = min(500,X_train.shape[1] )\n        k_best = SelectKBest(f_classif, k=self.n_features).fit(X_train, y_train)\n        self.X_train_kbest_valid=k_best.transform(X_train)\n        self.X_valid_kbest_valid=k_best.transform(X_test)\n        self.y_train_valid=y_train",
        "detail": "feature_algo.Genetic_FA",
        "documentation": {}
    },
    {
        "label": "contingency_table",
        "kind": 2,
        "importPath": "feature_algo.Genetic_FA",
        "description": "feature_algo.Genetic_FA",
        "peekOfCode": "def contingency_table(a,b,total):\n    obs = np.array([[a,total-a ], [b,total-b]])\n    chi2, p, dof, ex =chi2_contingency(obs)\n    if p>0.05:\n        return True\n    else:\n        return False\nclass Genetic_FA():\n    # def __init__(self ) -> None:\n    def fit(self,X,y):",
        "detail": "feature_algo.Genetic_FA",
        "documentation": {}
    },
    {
        "label": "error_rate",
        "kind": 2,
        "importPath": "feature_algo.New_dssa",
        "description": "feature_algo.New_dssa",
        "peekOfCode": "def error_rate(xt, xv, yt, yv, x):\n    # parameters\n    k = 5\n    # Number of instances\n    num_train = np.size(xt, 0)\n    num_valid = np.size(xv, 0)\n    # Define selected features\n    xtrain = xt[:, x == 1]\n    ytrain = yt.reshape(num_train)  # Solve bug\n    xvalid = xv[:, x == 1]",
        "detail": "feature_algo.New_dssa",
        "documentation": {}
    },
    {
        "label": "Fun",
        "kind": 2,
        "importPath": "feature_algo.New_dssa",
        "description": "feature_algo.New_dssa",
        "peekOfCode": "def Fun(xt, xv, yt, yv, x):\n    # Parameters\n    alpha = 0.99\n    beta = 1 - alpha\n    # Original feature size\n    max_feat = len(x)\n    # Number of selected features\n    num_feat = np.sum(x == 1)\n    # Solve if no feature selected\n    if num_feat == 0:",
        "detail": "feature_algo.New_dssa",
        "documentation": {}
    },
    {
        "label": "init_position",
        "kind": 2,
        "importPath": "feature_algo.New_dssa",
        "description": "feature_algo.New_dssa",
        "peekOfCode": "def init_position(lb, ub, N, dim):\n    M = 4\n    X = np.zeros([N, dim], dtype='float')\n    for i in range(N):\n        C = random.uniform(0, 1)\n        while C in [0.25, 0.5, 0.75]:\n            C = random.uniform(0, 1)\n        X[i, 0] = C\n        for d in range(1, dim):\n            X[i,d] = M * X[i, d-1] * (1 - X[i, d-1])",
        "detail": "feature_algo.New_dssa",
        "documentation": {}
    },
    {
        "label": "binary_conversion",
        "kind": 2,
        "importPath": "feature_algo.New_dssa",
        "description": "feature_algo.New_dssa",
        "peekOfCode": "def binary_conversion(X, thres, N, dim):\n    Xbin = np.zeros([N, dim], dtype='int')\n    for i in range(N):\n        for d in range(dim):\n            if X[i,d] > thres:\n                Xbin[i,d] = 1\n            else:\n                Xbin[i,d] = 0\n    return Xbin\ndef boundary(x, lb, ub):",
        "detail": "feature_algo.New_dssa",
        "documentation": {}
    },
    {
        "label": "boundary",
        "kind": 2,
        "importPath": "feature_algo.New_dssa",
        "description": "feature_algo.New_dssa",
        "peekOfCode": "def boundary(x, lb, ub):\n    if x < lb:\n        x = lb\n    if x > ub:\n        x = ub\n    return x\ndef LSA(fitF, Xbin, xt, xv, yt, yv, max_it = 10):\n    t1 = fitF\n    k = 1\n    while k <= max_it:",
        "detail": "feature_algo.New_dssa",
        "documentation": {}
    },
    {
        "label": "LSA",
        "kind": 2,
        "importPath": "feature_algo.New_dssa",
        "description": "feature_algo.New_dssa",
        "peekOfCode": "def LSA(fitF, Xbin, xt, xv, yt, yv, max_it = 10):\n    t1 = fitF\n    k = 1\n    while k <= max_it:\n        num_features = choice([2, 5])\n        feature_numbers = randint(0, Xbin.size, num_features)\n        for feature in feature_numbers:\n            if Xbin[feature] == 1:\n                Xbin[feature] = 0\n            else:",
        "detail": "feature_algo.New_dssa",
        "documentation": {}
    },
    {
        "label": "mutation",
        "kind": 2,
        "importPath": "feature_algo.New_dssa",
        "description": "feature_algo.New_dssa",
        "peekOfCode": "def mutation(N, dim, X, solution_num):\n    F = np.zeros([dim], dtype='float')\n    for i in range(dim):\n        F[i] = random.uniform(0.2, 0.8)\n    # pick 3 solutions that are not the current solution:\n    optional_i = [i for i in range(N) if i not in [solution_num]]\n    sources_i = random.sample(optional_i, 3)\n    # create the new mutation for solution i (X)\n    for i in range(dim):\n        X[solution_num, i] = X[sources_i[0], i] + F[i] * (X[sources_i[1], i] - X[sources_i[2], i])",
        "detail": "feature_algo.New_dssa",
        "documentation": {}
    },
    {
        "label": "fit",
        "kind": 2,
        "importPath": "feature_algo.New_dssa",
        "description": "feature_algo.New_dssa",
        "peekOfCode": "def fit(x, y):\n    # Parameters\n    ub    = 1\n    lb    = 0\n    thres = 0.5\n    N        = 10\n    max_iter = 100\n    M = random.uniform(0.9, 1.07)\n    U_Value = random.uniform(0, 1)\n    xtrain, xval, ytrain, yval = train_test_split(x, y, test_size=0.3)",
        "detail": "feature_algo.New_dssa",
        "documentation": {}
    },
    {
        "label": "error_rate",
        "kind": 2,
        "importPath": "feature_algo.dssa",
        "description": "feature_algo.dssa",
        "peekOfCode": "def error_rate(xt, xv, yt, yv, x):\n    # parameters\n    k = 5\n    # Number of instances\n    num_train = np.size(xt, 0)\n    num_valid = np.size(xv, 0)\n    # Define selected features\n    xtrain = xt[:, x == 1]\n    ytrain = yt.reshape(num_train)  # Solve bug\n    xvalid = xv[:, x == 1]",
        "detail": "feature_algo.dssa",
        "documentation": {}
    },
    {
        "label": "Fun",
        "kind": 2,
        "importPath": "feature_algo.dssa",
        "description": "feature_algo.dssa",
        "peekOfCode": "def Fun(xt, xv, yt, yv, x):\n    # Parameters\n    alpha = 0.99\n    beta = 1 - alpha\n    # Original feature size\n    max_feat = len(x)\n    # Number of selected features\n    num_feat = np.sum(x == 1)\n    # Solve if no feature selected\n    if num_feat == 0:",
        "detail": "feature_algo.dssa",
        "documentation": {}
    },
    {
        "label": "init_position",
        "kind": 2,
        "importPath": "feature_algo.dssa",
        "description": "feature_algo.dssa",
        "peekOfCode": "def init_position(lb, ub, N, dim):\n    X = np.zeros([N, dim], dtype='float')\n    for i in range(N):\n        for d in range(dim):\n            X[i,d] = lb[0,d] + (ub[0,d] - lb[0,d]) * rand()        \n    return X\ndef binary_conversion(X, thres, N, dim):\n    Xbin = np.zeros([N, dim], dtype='int')\n    for i in range(N):\n        for d in range(dim):",
        "detail": "feature_algo.dssa",
        "documentation": {}
    },
    {
        "label": "binary_conversion",
        "kind": 2,
        "importPath": "feature_algo.dssa",
        "description": "feature_algo.dssa",
        "peekOfCode": "def binary_conversion(X, thres, N, dim):\n    Xbin = np.zeros([N, dim], dtype='int')\n    for i in range(N):\n        for d in range(dim):\n            if X[i,d] > thres:\n                Xbin[i,d] = 1\n            else:\n                Xbin[i,d] = 0\n    return Xbin\ndef boundary(x, lb, ub):",
        "detail": "feature_algo.dssa",
        "documentation": {}
    },
    {
        "label": "boundary",
        "kind": 2,
        "importPath": "feature_algo.dssa",
        "description": "feature_algo.dssa",
        "peekOfCode": "def boundary(x, lb, ub):\n    if x < lb:\n        x = lb\n    if x > ub:\n        x = ub\n    return x\ndef LSA(fitF, Xbin, xt, xv, yt, yv, max_it = 10):\n    t1 = fitF\n    k = 1\n    while k <= max_it:",
        "detail": "feature_algo.dssa",
        "documentation": {}
    },
    {
        "label": "LSA",
        "kind": 2,
        "importPath": "feature_algo.dssa",
        "description": "feature_algo.dssa",
        "peekOfCode": "def LSA(fitF, Xbin, xt, xv, yt, yv, max_it = 10):\n    t1 = fitF\n    k = 1\n    while k <= max_it:\n        num_features = choice([2, 5])\n        feature_numbers = randint(0, Xbin.size, num_features)\n        for feature in feature_numbers:\n            if Xbin[feature] == 1:\n                Xbin[feature] = 0\n            else:",
        "detail": "feature_algo.dssa",
        "documentation": {}
    },
    {
        "label": "fit",
        "kind": 2,
        "importPath": "feature_algo.dssa",
        "description": "feature_algo.dssa",
        "peekOfCode": "def fit(x, y):\n    # Parameters\n    ub    = 1\n    lb    = 0\n    thres = 0.5\n    N        = 10\n    max_iter = 100\n    M = random.uniform(0.9, 1.08)\n    U_Value = rand()\n    xtrain, xval, ytrain, yval = train_test_split(x, y, test_size=0.3)",
        "detail": "feature_algo.dssa",
        "documentation": {}
    },
    {
        "label": "reliefF",
        "kind": 2,
        "importPath": "feature_algo.reliefF",
        "description": "feature_algo.reliefF",
        "peekOfCode": "def reliefF(X, y, mode=\"rank\", **kwargs):\n    \"\"\"\n    This function implements the reliefF feature selection\n    Input\n    -----\n    X: {numpy array}, shape (n_samples, n_features)\n        input data\n    y: {numpy array}, shape (n_samples,)\n        input class labels\n    kwargs: {dictionary}",
        "detail": "feature_algo.reliefF",
        "documentation": {}
    },
    {
        "label": "feature_ranking",
        "kind": 2,
        "importPath": "feature_algo.reliefF",
        "description": "feature_algo.reliefF",
        "peekOfCode": "def feature_ranking(score):\n    \"\"\"\n    Rank features in descending order according to reliefF score, the higher the reliefF score, the more important the\n    feature is\n    \"\"\"\n    idx = np.argsort(score, 0)\n    return idx[::-1]",
        "detail": "feature_algo.reliefF",
        "documentation": {}
    },
    {
        "label": "NoDaemonProcess",
        "kind": 6,
        "importPath": "utlis.utlis",
        "description": "utlis.utlis",
        "peekOfCode": "class NoDaemonProcess(Process):\n    def _get_daemon(self):\n        return False\n    def _set_daemon(self, value):\n        pass\n    daemon = property(_get_daemon, _set_daemon)\nclass MyPool(PoolParent):\n    Process = NoDaemonProcess",
        "detail": "utlis.utlis",
        "documentation": {}
    },
    {
        "label": "MyPool",
        "kind": 6,
        "importPath": "utlis.utlis",
        "description": "utlis.utlis",
        "peekOfCode": "class MyPool(PoolParent):\n    Process = NoDaemonProcess",
        "detail": "utlis.utlis",
        "documentation": {}
    },
    {
        "label": "get_fold",
        "kind": 2,
        "importPath": "utlis.utlis",
        "description": "utlis.utlis",
        "peekOfCode": "def get_fold(x):\n    if x<50:\n        return \"Leave-pair-out\"\n    elif x<=100:\n        return \"LOOCV\"\n    elif x<=1000:\n        return \"StratifiedKFold n_splits = 10\"\n    else:\n        return \"StratifiedKFold n_splits = 5\"\ndef turn_resDict_to_df(results,columns):",
        "detail": "utlis.utlis",
        "documentation": {}
    },
    {
        "label": "turn_resDict_to_df",
        "kind": 2,
        "importPath": "utlis.utlis",
        "description": "utlis.utlis",
        "peekOfCode": "def turn_resDict_to_df(results,columns):\n    all_df=[]\n    for algo_name,fs_algo_lst in list(results.items())[:-3]:\n        for k, k_res in list(fs_algo_lst.items())[:-1]:\n            fs_time= fs_algo_lst[\"fs_algo\"]\n            chosen_features= k_res[\"chosen_features\"]\n            feature_rank= k_res[\"feature_rank\"]\n            for clf_name,clf_res in list(k_res.items())[2:]:\n                for fold_name, fold_res in clf_res.items():\n                    infrence_time=fold_res[\"infrence_time\"]",
        "detail": "utlis.utlis",
        "documentation": {}
    },
    {
        "label": "freeze_seed",
        "kind": 2,
        "importPath": "augmentation",
        "description": "augmentation",
        "peekOfCode": "def freeze_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\nCLASSIFIERS = {'LogisticRegression': LogisticRegression(),\n            'RandomForestClassifier': RandomForestClassifier(),\n            'KNeighborsClassifier': KNeighborsClassifier(),\n            'GaussianNB': GaussianNB(),\n            'SVC': SVC(probability=True)}\ndef get_best_config(file_name):\n    \"\"\"",
        "detail": "augmentation",
        "documentation": {}
    },
    {
        "label": "get_best_config",
        "kind": 2,
        "importPath": "augmentation",
        "description": "augmentation",
        "peekOfCode": "def get_best_config(file_name):\n    \"\"\"\n    Get the best configuration for the given database and perform the augmentation\n    \"\"\"\n    head = ['index', 'value', 'infrence_time', 'Learning algorithm', 'Number of features selected (K)', 'chosen_features', 'Selected Features scores',\n            'Filtering Algorithm', 'Fold', 'fs_time', 'Dataset Name', 'Number of samples', 'Original Number of features', 'CV Method']\n    print(\"Processing file: \" + \" \" + file_name)\n    df = pd.read_csv(\"results/\"+file_name, header=0)\n    best_results = return_best_config(df)\n    feature_num = best_results['Number of features selected (K)']",
        "detail": "augmentation",
        "documentation": {}
    },
    {
        "label": "return_best_config",
        "kind": 2,
        "importPath": "augmentation",
        "description": "augmentation",
        "peekOfCode": "def return_best_config(df):\n    \"\"\"\n    Get the best configuration for the given database \n    \"\"\"\n    t = df[df[\"index\"]==\"AUC\"].groupby([\"Filtering Algorithm\",\"Number of features selected (K)\",\"Learning algorithm\"]).mean().reset_index()\n    t = t.sort_values(by=[\"value\"],ascending=False).iloc[0]\n    return t\ndef evaluate_augmentation(file_name, feature_num, classifier, fs_algorithm):\n    \"\"\"\n    preform the augmentation and evaluate the results",
        "detail": "augmentation",
        "documentation": {}
    },
    {
        "label": "evaluate_augmentation",
        "kind": 2,
        "importPath": "augmentation",
        "description": "augmentation",
        "peekOfCode": "def evaluate_augmentation(file_name, feature_num, classifier, fs_algorithm):\n    \"\"\"\n    preform the augmentation and evaluate the results\n    \"\"\"\n    db_name = file_name.split(\".\")[0].replace(\"_results\", \"\")\n    df = pd.read_csv(\"after_preprocess/\" + db_name + \".csv\", header=0)\n    X = df.iloc[:, :-1]\n    y = df.iloc[:, -1]\n    fold_func = get_fold(X)\n    y_prob_all = []",
        "detail": "augmentation",
        "documentation": {}
    },
    {
        "label": "run_cls",
        "kind": 2,
        "importPath": "augmentation",
        "description": "augmentation",
        "peekOfCode": "def run_cls(classifier, xtrain, ytrain, xtest, ytest):\n    \"\"\"\n    Run the classifier and return the results\"\"\"\n    start = timer()\n    cf = CLASSIFIERS[classifier].fit(xtrain, ytrain)\n    ypred = cf.predict_proba(xtest)\n    cls_time = timer() - start\n    return ypred, cls_time\ndef prep_results(res, cls_time, cls, k, chosen, chosen_scores, fs, fold, fs_time, df_name, size, all_features, cv_method,db_name):\n    \"\"\"",
        "detail": "augmentation",
        "documentation": {}
    },
    {
        "label": "prep_results",
        "kind": 2,
        "importPath": "augmentation",
        "description": "augmentation",
        "peekOfCode": "def prep_results(res, cls_time, cls, k, chosen, chosen_scores, fs, fold, fs_time, df_name, size, all_features, cv_method,db_name):\n    \"\"\"\n    Prepare the results for the csv file\n    \"\"\"\n    rows = []\n    for key, value in res.items():\n        rows.append([key, value, cls_time, cls, k, chosen, chosen_scores, fs, fold, fs_time, df_name, size, all_features, cv_method])\n    with open(\"augmenrataion_res/\"+db_name+\"augmentation.csv\", \"a\", newline=\"\") as fn:\n        write = csv.writer(fn)\n        write.writerows(rows)",
        "detail": "augmentation",
        "documentation": {}
    },
    {
        "label": "create_pca",
        "kind": 2,
        "importPath": "augmentation",
        "description": "augmentation",
        "peekOfCode": "def create_pca(feature_num, fs_algorithm, xtrain, xtest, ytrain, ytest):\n    \"\"\"\n    Create the PCA features and return them\n    \"\"\"\n    start = timer()\n    selected,time = feature_selection(fs_algorithm,xtrain.values, ytrain.values)\n    total = timer() - start\n    if fs_algorithm==\"ReliefF\":\n        k_best_index = np.argpartition(selected, -feature_num)[-feature_num:]\n        k_best_scores=selected[k_best_index]",
        "detail": "augmentation",
        "documentation": {}
    },
    {
        "label": "make_augmentation",
        "kind": 2,
        "importPath": "augmentation",
        "description": "augmentation",
        "peekOfCode": "def make_augmentation(xtrain, ytrain):\n    \"\"\"\n    perform Smote augmentations on the data\"\"\"\n    sm = over_sampling.SMOTE(k_neighbors=2,random_state=101)\n    X_res, Y_res = sm.fit_resample(xtrain, ytrain)\n    return  X_res, Y_res\nif __name__ == \"__main__\":\n    try:\n        task_n= int(os.environ['SLURM_ARRAY_TASK_ID'])\n    except KeyError:",
        "detail": "augmentation",
        "documentation": {}
    },
    {
        "label": "CLASSIFIERS",
        "kind": 5,
        "importPath": "augmentation",
        "description": "augmentation",
        "peekOfCode": "CLASSIFIERS = {'LogisticRegression': LogisticRegression(),\n            'RandomForestClassifier': RandomForestClassifier(),\n            'KNeighborsClassifier': KNeighborsClassifier(),\n            'GaussianNB': GaussianNB(),\n            'SVC': SVC(probability=True)}\ndef get_best_config(file_name):\n    \"\"\"\n    Get the best configuration for the given database and perform the augmentation\n    \"\"\"\n    head = ['index', 'value', 'infrence_time', 'Learning algorithm', 'Number of features selected (K)', 'chosen_features', 'Selected Features scores',",
        "detail": "augmentation",
        "documentation": {}
    },
    {
        "label": "get_clf_dict",
        "kind": 2,
        "importPath": "comparison",
        "description": "comparison",
        "peekOfCode": "def get_clf_dict():\n    return {'LogisticRegression': LogisticRegression(),\n            'RandomForestClassifier': RandomForestClassifier(),\n            'KNeighborsClassifier': KNeighborsClassifier(),\n            'GaussianNB': GaussianNB(),\n            'SVC': SVC(probability=True)}\nFS_ALGO_LIST= [\"dssa\",\"f_classif\",\"MRMR\",\"ReliefF\",\"New_dssa\",\"Genetic\",\"SVM\"]\nK_OPTIONS= [1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 50, 100]\ndef run_grid_search(db):\n    \"\"\"",
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "run_grid_search",
        "kind": 2,
        "importPath": "comparison",
        "description": "comparison",
        "peekOfCode": "def run_grid_search(db):\n    \"\"\"\n    run grid search on the all the configurations and return the best classifier\n    \"\"\"\n    X= db[:,:-1]\n    y= db[:,-1]\n    # septate each feature selection algorithm into a separate process \n    with MyPool(processes=len(FS_ALGO_LIST)) as pool:\n        results= pool.map(partial(calculate_per_FS_algo,X=X,y=y)\n                                  ,FS_ALGO_LIST)",
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "calculate_per_FS_algo",
        "kind": 2,
        "importPath": "comparison",
        "description": "comparison",
        "peekOfCode": "def calculate_per_FS_algo(fs_algo,X=[],y=[]):\n    \"\"\"\n    calculate the performance of each feature selection algorithm\n    \"\"\"\n    print(\"Calculating for {}\".format(fs_algo))\n    res={}\n    clf_list= get_clf_dict().items()\n    empty_feature=False\n    best_feature,fs_time = feature_selection(fs_algo,X, y)\n    res['fs_time']= fs_time",
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "k_level",
        "kind": 2,
        "importPath": "comparison",
        "description": "comparison",
        "peekOfCode": "def k_level(k,X,y,best_feature=[],ranking=False):\n    \"\"\"\n    calculate the performance of each feature selection algorithm for a given k value\n    \"\"\"\n    print(\"k level:\",k)\n    res={}\n    empty_feature= best_feature== []\n    clf_list= get_clf_dict().items()\n    if ranking:\n        k_best_index= best_feature[:k]",
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "evalute",
        "kind": 2,
        "importPath": "comparison",
        "description": "comparison",
        "peekOfCode": "def evalute(y_true,y_pred, y_prob, loo=False):\n    \"\"\"\n    evaluate the performance of the classifier results\n    \"\"\"\n    if y_prob.shape[1] ==2 or  y_prob.shape[1] ==1: #binary classification\n        if y_prob.shape[1] ==2:\n            y_prob= y_prob[:,1]\n        else:\n            y_prob= y_prob[:,0]\n        pr_auc= average_precision_score(y_true, y_prob)",
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "feature_selection",
        "kind": 2,
        "importPath": "comparison",
        "description": "comparison",
        "peekOfCode": "def feature_selection(fs_algo,X_train, y_train):\n    \"\"\"\n    preform feature selection algorithm on the training set and return the  feature score\n    \"\"\"\n    start = timer()\n    if  fs_algo==\"f_classif\":\n        return SelectFdr(score_func=f_classif,alpha=0.1).fit(X_train,y_train),timer()-start\n    elif fs_algo==\"MRMR\":\n        return SelectKBest(score_func=MRMR.mrmr,k=100).fit(X_train, y_train),timer()-start\n    elif fs_algo==\"ReliefF\":",
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "get_fold",
        "kind": 2,
        "importPath": "comparison",
        "description": "comparison",
        "peekOfCode": "def get_fold(x):\n    \"\"\"\n    return a fold function for cross validation defendant on the number of samples in the dataset\n    \"\"\"\n    if len(x)<50:\n        fold_func = LeavePOut(2)\n    elif len(x)<=100:\n        fold_func = LeavePOut(1)\n    elif len(x)<=1000:\n        fold_func = StratifiedKFold(n_splits=10)",
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "clf_res",
        "kind": 2,
        "importPath": "comparison",
        "description": "comparison",
        "peekOfCode": "def clf_res(res,clf):\n    clf_df= pd.DataFrame.from_dict(res)\n    clf_df.index = clf_df.index.set_names(['metric'])\n    clf_df.reset_index(inplace=True)\n    clf_df[\"Learning algorithm\"]= clf\n    return clf_df\nfrom  sklearn.model_selection import StratifiedKFold",
        "detail": "comparison",
        "documentation": {}
    },
    {
        "label": "imputation",
        "kind": 6,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "class imputation(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        self.X = X\n        imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n        X = imp_mean.fit_transform(X)\n        return X\n    def transform(self, X):\n        return self.X\n    def fit_transform(self, X, y=None):\n        X = self.fit(X)",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "variance",
        "kind": 6,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "class variance(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        scaler = StandardScaler()\n        X = scaler.fit_transform(X)\n        pt = PowerTransformer()\n        X = pt.fit_transform(X)\n        return X\n    def transform(self, X):\n        return self.X\n    def fit_transform(self, X, y=None):",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "fillna",
        "kind": 2,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "def fillna(X, y):\n    y = y.astype(str).astype(float)\n    y = y.fillna(y.max() + 1)\n    y = y.astype(int).values\n    return X, y\ndef read_bioconductor(db):\n    df = pd.read_csv(db, header=0)\n    df = df.T\n    cols = df.iloc[0, :]\n    cols = cols[1:]",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "read_bioconductor",
        "kind": 2,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "def read_bioconductor(db):\n    df = pd.read_csv(db, header=0)\n    df = df.T\n    cols = df.iloc[0, :]\n    cols = cols[1:]\n    df = df[1:]\n    X = df.iloc[:, 1:]\n    y = df.iloc[:, 0]\n    X, y = fillna(X, y)\n    X.columns = cols",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "read_scikit_mat",
        "kind": 2,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "def read_scikit_mat(db):\n    mat = scipy.io.loadmat(db)\n    X = mat['X']\n    X = pd.DataFrame(X)\n    y = mat['Y'][:, 0]\n    return X, y\ndef read_ARFF(db):\n    df = arff.loadarff(db)\n    df = pd.DataFrame(df[0])\n    X = df.iloc[:, :-1]",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "read_ARFF",
        "kind": 2,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "def read_ARFF(db):\n    df = arff.loadarff(db)\n    df = pd.DataFrame(df[0])\n    X = df.iloc[:, :-1]\n    y = df.iloc[:, -1]\n    return X, y\ndef read_datamicroarray(db):\n    df = pd.read_csv(db, header=None)\n    X = df.iloc[:, :-1]\n    y = df.iloc[:, -1]",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "read_datamicroarray",
        "kind": 2,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "def read_datamicroarray(db):\n    df = pd.read_csv(db, header=None)\n    X = df.iloc[:, :-1]\n    y = df.iloc[:, -1]\n    X, y = fillna(X, y)\n    return X, y\ndef read_and_fix(db):\n    function_name = {'bioconductor': read_bioconductor, 'scikit': read_scikit_mat, 'ARFF': read_ARFF, 'datamicroarray': read_datamicroarray}\n    file_type = db.split(\"/\")[1].split(\"_\")[0]\n    X, y = function_name[file_type](db)",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "read_and_fix",
        "kind": 2,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "def read_and_fix(db):\n    function_name = {'bioconductor': read_bioconductor, 'scikit': read_scikit_mat, 'ARFF': read_ARFF, 'datamicroarray': read_datamicroarray}\n    file_type = db.split(\"/\")[1].split(\"_\")[0]\n    X, y = function_name[file_type](db)\n    return X, y\ndef to_csv(X, y, name, cols):\n    suffix_name = name.split(\"/\")[1].split(\".\")[0]\n    df_array = np.column_stack((X,y))\n    df = pd.DataFrame(df_array)\n    cols = np.append(cols, \"label\")",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "to_csv",
        "kind": 2,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "def to_csv(X, y, name, cols):\n    suffix_name = name.split(\"/\")[1].split(\".\")[0]\n    df_array = np.column_stack((X,y))\n    df = pd.DataFrame(df_array)\n    cols = np.append(cols, \"label\")\n    df.to_csv('after_preprocess/' + suffix_name + \".csv\", index=False, header=cols)\npath = 'Data/'\nall_files = []\nfor file in os.listdir(path):\n    if os.path.isfile(os.path.join(path,file)):",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "path = 'Data/'\nall_files = []\nfor file in os.listdir(path):\n    if os.path.isfile(os.path.join(path,file)):\n        all_files.append(os.path.join(path,file))\nfor name in all_files:\n    X, y = read_and_fix(name)\n    cols = X.columns\n    label_encoder = LabelEncoder().fit(y)\n    y = label_encoder.transform(y)",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "all_files",
        "kind": 5,
        "importPath": "data_preprocessing",
        "description": "data_preprocessing",
        "peekOfCode": "all_files = []\nfor file in os.listdir(path):\n    if os.path.isfile(os.path.join(path,file)):\n        all_files.append(os.path.join(path,file))\nfor name in all_files:\n    X, y = read_and_fix(name)\n    cols = X.columns\n    label_encoder = LabelEncoder().fit(y)\n    y = label_encoder.transform(y)\n    pipe = Pipeline(steps=[('imputation', imputation()), ('variance_thresh', VarianceThreshold()), ('normalization', StandardScaler()),",
        "detail": "data_preprocessing",
        "documentation": {}
    },
    {
        "label": "freeze_seed",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def freeze_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\ndef main(database_name):\n    freeze_seed(42)\n    db=pd.read_csv(\"after_preprocess/\"+database_name+\".csv\",header=0)\n    columns=list(db.columns)\n    results=comparison.run_grid_search(db.values)\n    results[\"Dataset Name\"]=database_name\n    results[\"Number of samples\"]=db.shape[0]",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def main(database_name):\n    freeze_seed(42)\n    db=pd.read_csv(\"after_preprocess/\"+database_name+\".csv\",header=0)\n    columns=list(db.columns)\n    results=comparison.run_grid_search(db.values)\n    results[\"Dataset Name\"]=database_name\n    results[\"Number of samples\"]=db.shape[0]\n    results[\"Original Number of features\"]=db.shape[1]-1\n    #save results as csv file\n    results_csv= turn_resDict_to_df(results,columns)",
        "detail": "main",
        "documentation": {}
    }
]